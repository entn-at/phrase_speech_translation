#!/bin/bash
# Get the lattices from Kaldi for each dataset that has been decoded
# dev, dev2 and test : Fisher
# Acoustic scale set to 1/W, where W led to the best WER
# --- The symbols for laugh, noise and OOV , <unk> are hardcoded in the Kaldi2FST script. You should replace them (2035, 2038, 2039, 2040 in the default recipe)
# since they get replaced with eplison upon conversion
# --- Pruned with a beam width of 13.0
asr_util/kaldi2FST.sh \
  /export/a04/gkumar/code/kaldi-new \
  data/asr/dev/lattices \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_dev 0.067

asr_util/kaldi2FST.sh \
  /export/a04/gkumar/code/kaldi-new \
  data/asr/dev2/lattices \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_dev2 0.067

asr_util/kaldi2FST.sh \
  /export/a04/gkumar/code/kaldi-new \
  data/asr/test/lattices \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_test 0.067

# (OPTIONAL)
# Merge lattices based on timing information available
# Convert to PLF
asr_util/mainPLF.py -l data/asr/dev/lattices/lattices-pushed \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev -o data/asr/dev/plf \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim
asr_util/mainPLF.py -l data/asr/test/lattices/lattices-pushed \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/test \
  -o data/asr/test/plf \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim

# Get nbest files
nohup asr_util/kaldi2NBest.sh \
  /export/a04/gkumar/code/kaldi-new \
  data/asr/dev/nbest \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_dev \
  0.067 \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt > log/nbest_dev.out &

nohup asr_util/kaldi2NBest.sh \
  /export/a04/gkumar/code/kaldi-new \
  data/asr/dev2/nbest \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_dev2 \
  0.067 \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt > log/nbest_dev2.out &

nohup asr_util/kaldi2NBest.sh \
  /export/a04/gkumar/code/kaldi-new \
  data/asr/test/nbest \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_test \
  0.067 \
  /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt > log/nbest_test.out &

# Merge 1best files based on timing information
nohup asr_util/merge1Best.py \
  -i /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_dev/scoring/15.tra \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev \
  -o data/asr/dev/1best \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim > log/dev.1best.out &

nohup asr_util/merge1Best.py \
  -i /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_dev2/scoring/15.tra \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev2 \
  -o data/asr/dev2/1best \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim > log/dev2.1best.out &

nohup asr_util/merge1Best.py \
  -i /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri6a_dnn/decode_test/scoring/15.tra \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/test \
  -o data/asr/test/1best \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim > log/test.1best.out &

# Get the nbest files based on timing information
# awk '{s+=$1} END {print s}' asr.ncount
# to verify if the counts match the nbest hyps
nohup asr_util/mergeNBest.py \
  -i data/asr/dev/nbest/all.nbest \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev \
  -o data/asr/dev/nbest \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim > log/dev.nbest.merge.out &
nohup asr_util/mergeNBest.py \
  -i data/asr/dev2/nbest/all.nbest \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev2 \
  -o data/asr/dev2/nbest \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim > log/dev2.nbest.merge.out &
nohup asr_util/mergeNBest.py \
  -i data/asr/test/nbest/all.nbest \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/test \
  -o data/asr/test/nbest \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim > log/test.nbest.merge.out &

# Clean the 1-best files
asr_util/cleanASROutput.sh data/asr/dev/1best/asr.1best
asr_util/cleanASROutput.sh data/asr/dev2/1best/asr.1best
asr_util/cleanASROutput.sh data/asr/test/1best/asr.1best

# Clean the n-best files
asr_util/cleanASROutput.sh data/asr/dev/nbest/asr.nbest
asr_util/cleanASROutput.sh data/asr/dev2/nbest/asr.nbest
asr_util/cleanASROutput.sh data/asr/test/nbest/asr.nbest

# Generate reference for the n-best files
asr_util/replicateReference.py -c data/asr/dev/nbest/asr.ncount -r data/asr/dev/ref/fisher_dev.tok.lc.en.0 -o data/asr/dev/nbest/nbest.en.0
asr_util/replicateReference.py -c data/asr/dev/nbest/asr.ncount -r data/asr/dev/ref/fisher_dev.tok.lc.en.1 -o data/asr/dev/nbest/nbest.en.1
asr_util/replicateReference.py -c data/asr/dev/nbest/asr.ncount -r data/asr/dev/ref/fisher_dev.tok.lc.en.2 -o data/asr/dev/nbest/nbest.en.2
asr_util/replicateReference.py -c data/asr/dev/nbest/asr.ncount -r data/asr/dev/ref/fisher_dev.tok.lc.en.3 -o data/asr/dev/nbest/nbest.en.3
asr_util/replicateReference.py -c data/asr/dev2/nbest/asr.ncount -r data/asr/dev2/ref/fisher_dev2.tok.lc.en.0 -o data/asr/dev2/nbest/nbest.en.0
asr_util/replicateReference.py -c data/asr/dev2/nbest/asr.ncount -r data/asr/dev2/ref/fisher_dev2.tok.lc.en.1 -o data/asr/dev2/nbest/nbest.en.1
asr_util/replicateReference.py -c data/asr/dev2/nbest/asr.ncount -r data/asr/dev2/ref/fisher_dev2.tok.lc.en.2 -o data/asr/dev2/nbest/nbest.en.2
asr_util/replicateReference.py -c data/asr/dev2/nbest/asr.ncount -r data/asr/dev2/ref/fisher_dev2.tok.lc.en.3 -o data/asr/dev2/nbest/nbest.en.3
asr_util/replicateReference.py -c data/asr/test/nbest/asr.ncount -r data/asr/test/ref/fisher_test.tok.lc.en.0 -o data/asr/test/nbest/nbest.en.0
asr_util/replicateReference.py -c data/asr/test/nbest/asr.ncount -r data/asr/test/ref/fisher_test.tok.lc.en.1 -o data/asr/test/nbest/nbest.en.1
asr_util/replicateReference.py -c data/asr/test/nbest/asr.ncount -r data/asr/test/ref/fisher_test.tok.lc.en.2 -o data/asr/test/nbest/nbest.en.2
asr_util/replicateReference.py -c data/asr/test/nbest/asr.ncount -r data/asr/test/ref/fisher_test.tok.lc.en.3 -o data/asr/test/nbest/nbest.en.3

# Merge lattices
asr_util/mergeLattices.py -l data/asr/dev/lattices/lattices-pushed \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev -o data/asr/dev/mergedLat \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim
asr_util/mergeLattices.py -l data/asr/dev2/lattices/lattices-pushed \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/dev2 -o data/asr/dev2/mergedLat \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim
asr_util/mergeLattices.py -l data/asr/test/lattices/lattices-pushed \
  -s /export/a04/gkumar/code/kaldi-new/egs/fisher_callhome_spanish/s5/exp/tri5a/graph/words.txt \
  -c /export/a04/gkumar/corpora/fishcall/jack-splits/split-matt/test -o data/asr/test/mergedLat \
  -t /export/a04/gkumar/corpora/fishcall/fisher/tim

###############
# MT Steps
# TODO
# 1. How do you match vocabulary and symbol IDs with the ASR corpus
###############

# Decode n-best list
nohup mt_util/mosesFilterDecode.sh /export/a04/gkumar/experiments/is2015/8 \
  /export/a04/gkumar/code/custom/phrase_speech_translation/data/asr/dev/nbest/asr.nbest.clean \
  /export/a04/gkumar/experiments/is2015/5/tuning/moses.tuned.ini.1 \
  /export/a04/gkumar/experiments/is2015/5/model > log/decode.nbest.dev.out &

nohup mt_util/mosesFilterDecode.sh /export/a04/gkumar/experiments/is2015/6 \
  /export/a04/gkumar/code/custom/phrase_speech_translation/data/asr/dev2/nbest/asr.nbest.clean \
  /export/a04/gkumar/experiments/is2015/5/tuning/moses.tuned.ini.1 \
  /export/a04/gkumar/experiments/is2015/5/model > log/decode.nbest.dev2.out &

nohup mt_util/mosesFilterDecode.sh /export/a04/gkumar/experiments/is2015/7 \
  /export/a04/gkumar/code/custom/phrase_speech_translation/data/asr/test/nbest/asr.nbest.clean \
  /export/a04/gkumar/experiments/is2015/5/tuning/moses.tuned.ini.1 \
  /export/a04/gkumar/experiments/is2015/5/model > log/decode.nbest.test.out &

# Convert the Moses phrase table to an FST
mt_util/phraseTable2FST.py -p /export/a04/gkumar/experiments/is2015/1/model/phrase-table.1.gz -f data/mt/phrase-table.fst.txt -s data/mt/syms.txt
# Compile this fst
fstcompile data/mt/phrase-table.fst.txt data/mt/phrase-table.fst.bin

##############
# Interface steps
# ############
# To get sentence level BLEU
/export/a04/gkumar/code/mosesdecoder/bin/sentence-bleu refs... < cand
